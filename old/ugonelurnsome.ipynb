{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39915ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from itertools import islice, chain\n",
    "from functools import reduce , wraps\n",
    "import io\n",
    "from typing import Dict, List, Optional\n",
    "from operator import eq, ne, lt, le, gt, ge, add, sub, mul, truediv\n",
    "from operator import concat as str_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "647c3c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Arsenal', '38', '26', '9', '3', '79', '36', '87'], ['Liverpool', '38', '24', '8', '6', '67', '30', '80'], ['Leeds', '38', '18', '12', '8', '53', '37', '66'], ['Chelsea', '38', '17', '13', '8', '66', '38', '64']]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/matebarey/Downloads/repos/mozity')\n",
    "\n",
    "\n",
    "file_name  = \"football.csv\"\n",
    "file_name2 = \"weather.csv\"\n",
    "#phase 1  load and understand\n",
    "\n",
    "def view_from_predicate(fn):\n",
    "    @wraps(fn)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        pred = fn(self, *args, **kwargs)\n",
    "        rows = self.get_rows()\n",
    "        return filter(pred, rows)  # or list(filter(...)) for eager\n",
    "    return wrapper\n",
    "\n",
    "# detect and stirp bom  with utf-8-sig\n",
    "def mutating(fn):\n",
    "    @wraps(fn)\n",
    "    def wrapper(self, *args, mutate=False, output_col=None, **kwargs):\n",
    "        base_rows = self.get_rows()\n",
    "        result_gen = list(fn(self, *args, **kwargs))  # Force evaluation\n",
    "\n",
    "        if mutate:\n",
    "            if not output_col:\n",
    "                raise ValueError(\"Must specify output_col when mutating\")\n",
    "            if self.has_headers and output_col not in self._headers:\n",
    "                self._headers.append(output_col)\n",
    "\n",
    "            return (row + [val] for row, val in zip(base_rows, result_gen))\n",
    "        else:\n",
    "            return result_gen\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "# pandas polars default is interpret utf8 if they cant decoe  they thorw code error\n",
    "def clean_csv_bytes(b: bytes) -> bytes :\n",
    "    fixes = {\n",
    "        'crlf': (rb'\\r\\n', b'\\n'),\n",
    "        'cr': (rb'\\r(?!\\n)', b'\\n'),\n",
    "        'bom_start': (rb'^\\xef\\xbb\\xbf', b''),\n",
    "        'bom_interior': (b'\\xef\\xbb\\xbf', b''),\n",
    "        'null': (b'\\x00', b''),\n",
    "        'sep_header': (rb'(?i)^sep=.*?\\n', b''),\n",
    "        'curly_quotes_open': (b'\\xe2\\x80\\x9c', b'\"'),\n",
    "        'curly_quotes_close': (b'\\xe2\\x80\\x9d', b'\"'),\n",
    "        'curly_single_open': (b'\\xe2\\x80\\x98', b\"'\"),\n",
    "        'curly_single_close': (b'\\xe2\\x80\\x99', b\"'\"),\n",
    "        'grave_accent': (b'\\x60', b\"'\"),\n",
    "        'acute_accent': (b'\\xc2\\xb4', b\"'\"),\n",
    "        'unescaped_quotes': (rb'(?<!^)(?<!,)\"(?!,)(?!$)(?!\")', b'\"\"')\n",
    "    }\n",
    "\n",
    "    # Single comprehension: count and apply fixes if count > 0\n",
    "    return reduce(\n",
    "        lambda content, fix: re.sub(fix[0], fix[1], content),\n",
    "        [fix for fix in fixes.values() if len(re.findall(fix[0], b)) > 0],\n",
    "        b\n",
    "    )\n",
    "def logical_and(pred1, pred2):\n",
    "    def combined(row):\n",
    "        return pred1(row) and pred2(row)\n",
    "    return combined\n",
    "def str_concat(a,b):\n",
    "    return str(a) + str(b)\n",
    "def logical_or(pred1, pred2):\n",
    "    def combined(row):\n",
    "        return pred1(row) or pred2(row)\n",
    "    return combined\n",
    "\n",
    "def logical_not(pred):\n",
    "    def inverted(row):\n",
    "        return not pred(row)\n",
    "    return inverted\n",
    "\n",
    "class SafeBinder:\n",
    "    def __init__(self, value=None, status=None):\n",
    "        self.value = value\n",
    "        self.status = status\n",
    "\n",
    "    def bind(self,f):\n",
    "        if self.status is not None :\n",
    "            return SafeBinder(None,self.status)\n",
    "\n",
    "        try:\n",
    "            result = f(self.value)\n",
    "            return SafeBinder(result,None)\n",
    "        except Exception as e:\n",
    "            return SafeBinder(None, e)\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.value\n",
    "\n",
    "class ParseCSV:\n",
    "    def __init__(self,file_path,has_headers=True, chunk_threshold=1000):\n",
    "        self.data = file_path\n",
    "        self.has_headers = has_headers\n",
    "        self.chunk_threshold = chunk_threshold\n",
    "        self._sampling_cache = []\n",
    "        self._went_lazy = False\n",
    "        self._cmp_ops   = {\"eq\": eq, \"==\": eq, \"ne\": ne, \"!=\": ne,\n",
    "                           \"lt\": lt, \"<\": lt, \"le\": le, \"<=\": le,\n",
    "                           \"gt\": gt, \">\": gt, \"ge\": ge, \">=\": ge}\n",
    "        self._arith_ops = {\"+\": add, \"-\": sub, \"*\": mul, \"/\": truediv, \"concat\": str_concat}\n",
    "        self._logical_ops = {\n",
    "            \"and\": logical_and,\n",
    "            \"or\": logical_or,\n",
    "            \"not\": logical_not\n",
    "        }\n",
    "\n",
    "        self.encodings = ['utf-8-sig', 'utf-8', 'latin1']\n",
    "        self._headers = []\n",
    "\n",
    "    #design plan  3 layers\n",
    "\n",
    "    #build , combine, run\n",
    "\n",
    "\n",
    "    def apply_op(self, op):\n",
    "        def applied(*args):\n",
    "            # Call op *inside* bind so exceptions are caught\n",
    "            return SafeBinder(args).bind(lambda xs: op(*xs))\n",
    "        return applied\n",
    "\n",
    "    def _identity(self, x):\n",
    "        return x\n",
    "\n",
    "    def gen_search(self, colA, op, colB=None, value=None):\n",
    "        pred = self.gen_search_pred(colA, op, colB, value)\n",
    "        return self.run_search(pred)\n",
    "\n",
    "    def run_search(self, predicate, rows=None):\n",
    "        row_stream = rows if rows is not None else self.get_rows()\n",
    "        return filter(predicate, row_stream)\n",
    "\n",
    "    def make_predicate(self, accessor, apply_op, right_value=None):\n",
    "        def predicate(row):\n",
    "            a, b = accessor(row)\n",
    "            rhs = right_value if right_value is not None else b\n",
    "            return apply_op(a, rhs)()\n",
    "        return predicate\n",
    "\n",
    "    def make_coercer(self):\n",
    "        def _coerce(val):\n",
    "            return float(val) if '.' in val else int(val)\n",
    "\n",
    "        return self.apply_op(_coerce)\n",
    "\n",
    "    def gen_search_pred(self, colA, op, colB=None, value=None):\n",
    "        self._validate_search(colA, op, colB, value)\n",
    "        self._validate_column(colA)\n",
    "        if colB:\n",
    "            self._validate_column(colB)\n",
    "\n",
    "        idxA = self._headers.index(colA)\n",
    "        idxB = self._headers.index(colB) if colB else None\n",
    "\n",
    "        accessor = self.make_row_accessor(idxA, idxB, coerce=True)\n",
    "        op_applier = self.apply_op(self._cmp_ops[op])\n",
    "\n",
    "        return self.make_predicate(accessor, op_applier, value)\n",
    "\n",
    "\n",
    "    def make_row_accessor(self, idxA, idxB=None, coerce=False):\n",
    "        coerce_fn = self.make_coercer() if coerce else None\n",
    "\n",
    "        def accessor(row):\n",
    "            if coerce_fn is None:\n",
    "                a = row[idxA]\n",
    "                b = row[idxB] if idxB is not None else None\n",
    "            else:\n",
    "                a = coerce_fn(row[idxA])()\n",
    "                b = coerce_fn(row[idxB])() if idxB is not None else None\n",
    "            return a, b\n",
    "        return accessor\n",
    "\n",
    "    def is_lazy_mode(self):\n",
    "        return self._went_lazy\n",
    "\n",
    "    def _validate_search(self, colA, op, colB, value):\n",
    "        if not colA or not op:\n",
    "            raise ValueError(\"colA and op are required\")\n",
    "        if colB is None and value is None:\n",
    "            raise ValueError(\"Either colB or value must be provided\")\n",
    "        if colB is not None and value is not None:\n",
    "            raise ValueError(\"Provide either colB or value, not both\")\n",
    "\n",
    "\n",
    "            # there is no value  but there is col A and col B a\n",
    "    @mutating\n",
    "    def apply_arith(self, colA, op, colB=None, value=None):\n",
    "        if not self._headers:\n",
    "            _ = self.get_rows()\n",
    "\n",
    "        idxA = self._headers.index(colA)\n",
    "        idxB = self._headers.index(colB) if colB else None\n",
    "        op_fn = self._arith_ops[op]  # <- JUST the raw function\n",
    "\n",
    "        is_math = op in {\"+\", \"-\", \"*\", \"/\"}\n",
    "        coerce = self.make_coercer() if is_math else self._identity\n",
    "\n",
    "        def transformer(row):\n",
    "            a_raw = row[idxA]\n",
    "            b_raw = row[idxB] if colB else value\n",
    "\n",
    "            try:\n",
    "                a = coerce(a_raw)() if is_math else a_raw\n",
    "                b = coerce(b_raw)() if (colB and is_math) else b_raw\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Coercion failed: {e} | Row: {row}\")\n",
    "                return None\n",
    "\n",
    "            try:\n",
    "                return op_fn(a, b)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Operation failed: {a} {op} {b} | Error: {e}\")\n",
    "                return None\n",
    "\n",
    "        return (transformer(row) for row in self.get_rows())\n",
    "\n",
    "\n",
    "\n",
    "    def combine_search(self, preds, logic='and'):\n",
    "        logic = logic.lower()\n",
    "        op_func = self._logical_ops[logic]\n",
    "        return op_func(*preds)\n",
    "\n",
    "\n",
    "    def _validate_column(self, col_name: str):\n",
    "        if not self._headers:\n",
    "            _ = self.get_rows()  # ensures headers are loaded\n",
    "        if col_name not in self._headers:       # <-- fix: remove self.self\n",
    "            raise ValueError(f\"Column '{col_name}' not found. Available: {self._headers}\")\n",
    "\n",
    "    def get_column(self, col_name):\n",
    "        if not self._headers:\n",
    "            _ = self.get_rows()  # ensure headers are loaded\n",
    "        if col_name not in self._headers:\n",
    "            raise ValueError(f\"Column '{col_name}' not found. Available: {self._headers}\")\n",
    "\n",
    "        idx = self._headers.index(col_name)\n",
    "        return [row[idx] for row in self.get_rows()]\n",
    "\n",
    "    def mutate_and_cache(self, *args, **kwargs):\n",
    "        result = list(self.apply_arith(*args, **kwargs))\n",
    "        self._sampling_cache = result\n",
    "        return result\n",
    "\n",
    "    def _validate_operator(self, op):\n",
    "        \"\"\"Validate that operator is callable and supported\"\"\"\n",
    "        if not callable(op):\n",
    "            raise ValueError(f\"Operator must be callable, got {type(op)}\")\n",
    "\n",
    "        # Optional: Check if it's a known comparison operator\n",
    "\n",
    "        if op not in self._cmp_ops:\n",
    "            # Warn but don't fail - user might have custom operators\n",
    "            print(f\"Warning: Uncommon operator {op}. Use standard comparison operators for best results.\")\n",
    "\n",
    "    def get_rows(self):  # lazy after reading file into memory\n",
    "        raw = self._raw_rows()\n",
    "        rows = self._set_headers(raw)  # ensure headers are set here\n",
    "        first_chunk = list(islice(rows, self.chunk_threshold))\n",
    "        self._sampling_cache = first_chunk\n",
    "        self._went_lazy = len(first_chunk) >= self.chunk_threshold\n",
    "        return chain(iter(first_chunk), rows) if self._went_lazy else iter(first_chunk)\n",
    "\n",
    "    def _set_headers(self, rows):\n",
    "        first = next(rows, None)\n",
    "        if not first:\n",
    "            self._headers = []\n",
    "            return iter([])\n",
    "\n",
    "        # User specified or default to numeric\n",
    "        if hasattr(self, 'has_headers') and self.has_headers:\n",
    "            self._headers = first\n",
    "            return rows\n",
    "        else:\n",
    "            self._headers = list(range(len(first)))\n",
    "            return chain([first], rows)\n",
    "\n",
    "    def _raw_rows(self):\n",
    "        content = self._read_file()\n",
    "        return (row for row in csv.reader(content.splitlines()))\n",
    "\n",
    "    def _read_file(self):\n",
    "        return next(\n",
    "            (r() for r in (SafeBinder(self.data).bind(lambda f: open(f, 'r', encoding=enc).read())\n",
    "                        for enc in self.encodings)\n",
    "            if r.status is None),\n",
    "            SafeBinder(self.data).bind(lambda f: clean_csv_bytes(open(f, 'rb').read()).decode('utf-8'))()\n",
    "        )\n",
    "\n",
    "parser_csv = ParseCSV(file_path=file_name,has_headers=True)\n",
    "new_col = list(parser_csv.mutate_and_cache(\"Goals\",\"-\",\"Goals Allowed\",mutate=True,output_col=\"sum\"))\n",
    "#new_col = list(parser_csv(\"Goals\",\"-\",\"Goals Allowed\"))\n",
    "double_points = list(parser_csv.apply_arith(\"Points\", \"*\", value=2))\n",
    "concat_col = list(parser_csv.apply_arith(\"Team\", \"concat\", value=\" FC\"))\n",
    "p1 = parser_csv.gen_search_pred(\"Goals\", \">\", value=50)\n",
    "p2 = parser_csv.gen_search_pred(\"Goals Allowed\", \"<\", value=40)\n",
    "combined = parser_csv.combine_search([p1, p2], logic=\"and\")\n",
    "view = parser_csv.run_search(combined)\n",
    "print(list(view))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c637f6",
   "metadata": {},
   "source": [
    "ðŸ§  What is a decorator?\n",
    "\n",
    "A decorator is just a function that takes another function, wraps it in something (like logging, safety, timing, caching, etc.), and returns a new function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba750e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decorator style\n",
    "def my_decorator(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        print(\"Before\")\n",
    "        result = f(*args, **kwargs)\n",
    "        print(\"After\")\n",
    "        return result\n",
    "    return wrapped\n",
    "\n",
    "@my_decorator\n",
    "def greet(name):\n",
    "    print(f\"Hello, {name}\")\n",
    "\n",
    "\n",
    "# this is syntactic sugar for\n",
    "greet = my_decorator(greet)\n",
    "\n",
    "'''\n",
    "âœ… What is a closure?\n",
    "so closure is just something tha captures.. so my safebinder and your .. way to bypass execution for later .. so we took another fn that swallowed hte other fns stuff so its a closure as well. .. and decorator is a form of a closure and some times lambda can be closures depending on if htey swallow stuff up ?\n",
    "\n",
    "A closure is a function that captures variables from its surrounding scope, keeping them \"alive\" even after the outer function has returned.\n",
    "\n",
    "âž• Can be:\n",
    "\n",
    "A named def function\n",
    "\n",
    "A lambda / anonymous function\n",
    "\n",
    "A class with __call__\n",
    "\n",
    "A decorator\n",
    "\n",
    "Anything that returns a function that still \"remembers\" outside variables\n",
    "\n",
    "ðŸ” What counts as a closure?\n",
    "Example\tClosure?\tWhy?\n",
    "lambda x: x + y (where y is outer)\tâœ… Yes\tCaptures y from outer scope\n",
    "SafeBinder().bind(...)\tâœ… Yes\tbind() returns a wrapped fn that \"remembers\" the value\n",
    "make_evaluator() inner eval_row()\tâœ… Yes\tIt remembers accessor, apply_op, right_value\n",
    "A decorator that wraps another fn\tâœ… Yes\tIt captures and modifies behavior while holding outside vars\n",
    "A lambda with no outer vars\tâŒ No\tIt's just an anonymous fn, not a closure\n",
    "\n",
    "\n",
    "So in your code:\n",
    "\n",
    "Your apply_op(...) returns a lambda that remembers op\n",
    "âœ… That's a closure\n",
    "\n",
    "make_evaluator(...) returns a function that remembers accessor, apply_op, right_value\n",
    "âœ… Closure\n",
    "\n",
    "SafeBinder().bind(...) returns a wrapper function that wraps evaluation and error catching\n",
    "âœ… Closure\n",
    "\n",
    "A decorator is basically:\n",
    "def decorator(f):\n",
    "    def wrapped(*args):  # â† closure\n",
    "        return f(*args)\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "ðŸ§  TL;DR (Write this down somewhere):\n",
    "\n",
    "A closure is not about how you write the function (lambda vs def) â€” it's about whether that function remembers and uses variables from outside its own local scope.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8714929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "df['Net'] = df['Goals'] - df['Goals Allowed']\n",
    "df.Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9297d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dpoints\"] = df[\"Points\"] * 2\n",
    "df.dpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "06baea1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Games</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Draws</th>\n",
       "      <th>Goals</th>\n",
       "      <th>Goals Allowed</th>\n",
       "      <th>Points</th>\n",
       "      <th>Net</th>\n",
       "      <th>dpoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>36</td>\n",
       "      <td>87</td>\n",
       "      <td>43</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "      <td>28</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team  Games  Wins  Losses  Draws  Goals  Goals Allowed  Points  Net  \\\n",
       "0    Arsenal     38    26       9      3     79             36      87   43   \n",
       "1  Liverpool     38    24       8      6     67             30      80   37   \n",
       "4      Leeds     38    18      12      8     53             37      66   16   \n",
       "5    Chelsea     38    17      13      8     66             38      64   28   \n",
       "\n",
       "   dpoints  \n",
       "0      174  \n",
       "1      160  \n",
       "4      132  \n",
       "5      128  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"Goals\"] > 50) & ( df[\"Goals Allowed\"] <40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e6b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
